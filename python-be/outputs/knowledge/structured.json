{
  "markdown": [
    {
      "identifier": "asset_catalogs.md",
      "title": "Asset Catalogs",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\asset_catalogs.md",
      "headings": [
        [
          "Asset Catalog Integration",
          1
        ],
        [
          "Catalog Overview",
          2
        ],
        [
          "Usage Guidelines",
          2
        ],
        [
          "Integration Touchpoints",
          2
        ]
      ],
      "sections": [
        "This document details how asset catalogs are integrated into the video automation pipeline. It ensures that the AI model's outputs can be directly mapped to available production assets, guaranteeing the generation of actionable and feasible video plans.\nConnect model outputs with available production assets to guarantee actionable plans.",
        "File\nPurpose\nKey Fields\n`assets/broll_catalog.json`\nInventory of stills and footage for b-roll replacement shots.\n`id`, `title`, `file`, `mediaType`, `orientation`, `tags`, `mood`, `usageExamples`.\n`assets/sfx_catalog.json`\nLibrary of sound effects indexed by mood and cue type.\n`id`, `file`, `length`, `intensity`, `tags`, `recommendedContexts`.\n`assets/motion_rules.json`\nAllowed transitions and motion presets with usage rules.\n`id`, `action`, `layer`, `minSpacing`, `pairings`.\n`assets/context_rules.json`\nMapping from narrative contexts to preferred asset tags.\n`context`, `recommendedBrollTags`, `recommendedSfxTags`, `notes`.",
        "**Match by Context Tags** - ensure each generated element includes `context` (see `element_schema.json`). Use it to query `context_rules.json` and retrieve permitted `broll` or `sfx` tags.\n**Validate Asset Availability** - before finalising a plan, confirm `description` or `sound` values map to existing `id`s in the relevant catalog; log fallback suggestions when no exact match is found.\n**Respect Motion Constraints** - defer to `motion_rules.json` for allowable sequences (for example, minimum 0.5 s spacing between identical zooms).\n**Enrich Training Examples** - augment training data with catalog metadata (for example, embed `mood` vectors) so the model learns to pick assets aligned with emotional tone.\n**Keep Catalogs Synced** - update version numbers and regeneration timestamps when assets change; propagate updates to downstream caches.",
        "**Feature Engineering** - include catalog tags as additional inputs when predicting `description` or `sound`.\n**Inference** - post-process model outputs by selecting the closest matching `id` using cosine similarity between description embeddings and catalog tags.\n**Evaluation** - add assertions in `quality_criteria.md` to confirm selected assets exist and comply with `motion_rules.json`.\nRefer back to `knowledge-base/data_sources.md` for provenance and to `planning_guidelines.md` for contextual placement rules."
      ],
      "metadata": {}
    },
    {
      "identifier": "CHANGELOG.md",
      "title": "Changelog",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\CHANGELOG.md",
      "headings": [
        [
          "Changelog",
          1
        ],
        [
          "2025-10-21",
          2
        ]
      ],
      "sections": [
        "All notable changes to the AI planning knowledge base will be documented in this file.",
        "Added `element_schema.json` to formalise element structure, allowed values, and validation rules.\nExpanded `examples/` with qualitative (`patterns.md`) and structured (`patterns.json`) cases, including edge and negative scenarios.\nIntroduced `asset_catalogs.md` and documented catalog usage in `data_sources.md`.\nRefined `planning_guidelines.md` with cross-references, rationales, and motion spacing rules.\nUpgraded video outlines to narrative blueprints with summaries, audiences, and emotional tone guidance.\nExpanded `glossary.md` to cover modelling terminology (Sentence-BERT, MAE, F1, etc.).\nUpdated `README.md` with new directory map and versioning instructions."
      ],
      "metadata": {}
    },
    {
      "identifier": "data_sources.md",
      "title": "Data Sources",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\data_sources.md",
      "headings": [
        [
          "Data Sources",
          1
        ],
        [
          "Extraction Reminders",
          3
        ]
      ],
      "sections": [
        "This document provides a comprehensive overview of all data sources utilized in the AI video automation pipeline. Understanding these sources is crucial for comprehending how the AI learns, generates, and validates video plans. Each source plays a distinct role in the overall process, from raw transcripts to structured asset catalogs.\nSource\nRole in pipeline\nNotable details\n`AI_Training_Plan.md`\nMaster plan for curating datasets, extracting features, training and evaluating models.\nWritten in Vietnamese; covers nine stages from data auditing to deployment and includes risk mitigation notes.\n`transcript_video_1.txt`\nFull transcript with timestamps for *How I Would Learn Digital Marketing (If I Could Start Over)*.\nHighlights speaker journey, three-part learning framework, practice principles, and career path discussion.\n`video1.json`\nAnnotated timeline aligned to `transcript_video_1.txt`.\n188 timestamp entries plus `video_metadata` with element glossaries, layering rules, editing patterns, and AI-specific notes.\n`transcript_video_2.txt`\nTranscript and timing for *Digital Marketing 101 (A Beginner's Guide to Marketing)*.\nExplains foundational marketing concepts, channel definitions, and comparison frameworks (digital vs. traditional, B2B vs. B2C, products vs. services).\n`video2.json`\nTimeline annotations for `transcript_video_2.txt`.\nEmphasis on text overlays with highlighted backgrounds, frequent zoom transitions, and context fields describing intent of each element.\nAsset catalogs (`assets/*.json`)\nAuthoritative source for available b-roll, motion, and SFX assets.\nDocumented in detail inside [asset_catalogs.md](asset_catalogs.md); include tags, moods, and usage constraints used during inference.",
        "Keep transcript timestamps in `M:SS` and convert to seconds during preprocessing.\nPreserve `context`, `style`, `animation`, and `sound` attributes; they contain supervision signals even when absent from transcripts.\nWhen augmenting data, cross-link transcript spans to timeline entries via timestamp proximity (+/- 1 second window works for both videos).\nTrack narrative sections (e.g., `Part 1`, `B2B vs B2C`) to help the model learn context-aware element placement.\nSynchronise with asset catalogs so generated descriptions map to real `id`s and comply with motion spacing rules."
      ],
      "metadata": {}
    },
    {
      "identifier": "element_definitions.md",
      "title": "Element Definitions",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\element_definitions.md",
      "headings": [
        [
          "Element Definitions & Layering Rules",
          1
        ],
        [
          "Element Families",
          2
        ],
        [
          "`broll`",
          3
        ],
        [
          "`text_overlay`",
          3
        ],
        [
          "`text_animation`",
          3
        ],
        [
          "`sound_effect`",
          3
        ],
        [
          "`effect`",
          3
        ],
        [
          "`icon`",
          3
        ],
        [
          "`speaker_intro`, `achievement_highlight`, `section_header`, `emphasis`",
          3
        ],
        [
          "Layer Stack",
          2
        ],
        [
          "Synchronisation Notes",
          2
        ],
        [
          "Automation Rule Updates",
          2
        ]
      ],
      "sections": [
        "This document outlines the various video elements used in the automation pipeline, their purposes, and the rules governing their placement and layering. These definitions are compiled from `video1.json`, `video2.json`, and other production metadata, providing a consistent framework for AI-generated video plans. For machine-readable constraints and validation rules, refer to [element_schema.md](element_schema.md).",
        "",
        "**Purpose** - Cung c\u1ea5p c\u1ea3nh quay b\u1ed5 sung (b-roll) \u0111\u1ec3 minh h\u1ecda ho\u1eb7c c\u1ee7ng c\u1ed1 \u00fd t\u01b0\u1edfng \u0111ang \u0111\u01b0\u1ee3c n\u00f3i, gi\u00fap t\u0103ng c\u01b0\u1eddng s\u1ef1 h\u1ea5p d\u1eabn th\u1ecb gi\u00e1c v\u00e0 truy\u1ec1n t\u1ea3i th\u00f4ng \u0111i\u1ec7p hi\u1ec7u qu\u1ea3 h\u01a1n.\n**Layer** - `video` (thay th\u1ebf ho\u1eb7c ph\u1ee7 l\u00ean ngu\u1ed3n c\u1ea5p d\u1eef li\u1ec7u ch\u00ednh c\u1ee7a ng\u01b0\u1eddi n\u00f3i).\n**Key fields** - `description` (m\u00f4 t\u1ea3 n\u1ed9i dung b-roll), `context` (ng\u1eef c\u1ea3nh s\u1eed d\u1ee5ng), optional `tags` (c\u00e1c th\u1ebb ph\u00e2n lo\u1ea1i \u0111\u1ec3 t\u00ecm ki\u1ebfm v\u00e0 kh\u1edbp v\u1edbi kho t\u00e0i s\u1ea3n).\n**Defaults** - Ph\u00e1t cho \u0111\u1ebfn khi m\u1ed9t ph\u1ea7n t\u1eed l\u1edbp `video` kh\u00e1c xu\u1ea5t hi\u1ec7n ho\u1eb7c d\u00f2ng th\u1eddi gian quay tr\u1edf l\u1ea1i l\u1edbp `main`.",
        "**Purpose** - Hi\u1ec3n th\u1ecb v\u0103n b\u1ea3n tr\u00ean m\u00e0n h\u00ecnh v\u1edbi ki\u1ec3u d\u00e1ng th\u01b0\u01a1ng hi\u1ec7u, d\u00f9ng \u0111\u1ec3 l\u00e0m n\u1ed5i b\u1eadt th\u00f4ng tin quan tr\u1ecdng, ti\u00eau \u0111\u1ec1, ho\u1eb7c c\u00e1c \u0111i\u1ec3m nh\u1ea5n.\n**Layer** - `overlay` (l\u1edbp ph\u1ee7).\n**Key fields** - `content` (n\u1ed9i dung v\u0103n b\u1ea3n), `style` (ki\u1ec3u d\u00e1ng hi\u1ec3n th\u1ecb), `animation` (hi\u1ec7u \u1ee9ng \u0111\u1ed9ng khi xu\u1ea5t hi\u1ec7n/bi\u1ebfn m\u1ea5t).\n**Common styles** - `simple_text` (ch\u1ec9 v\u0103n b\u1ea3n, \u0111\u01a1n gi\u1ea3n), `section_box` (h\u1ed9p ch\u1ee9a v\u0103n b\u1ea3n k\u00e8m hi\u1ec7u \u1ee9ng \u0111\u1ed9ng cho c\u00e1c \u0111o\u1ea1n chia \u0111i\u1ec3m).\n**Defaults** - Duy tr\u00ec hi\u1ec3n th\u1ecb cho \u0111\u1ebfn khi c\u00f3 l\u1edbp ph\u1ee7 ti\u1ebfp theo ho\u1eb7c thay \u0111\u1ed5i ng\u1eef c\u1ea3nh.",
        "**Purpose** - T\u1ea1o hi\u1ec7u \u1ee9ng ho\u1ea1t h\u00ecnh cho v\u0103n b\u1ea3n, th\u01b0\u1eddng d\u00f9ng \u0111\u1ec3 hi\u1ec3n th\u1ecb s\u1ed1 \u0111\u1ebfm, ti\u1ebfn tr\u00ecnh, ho\u1eb7c nh\u1ea5n m\u1ea1nh c\u00e1c t\u1eeb kh\u00f3a quan tr\u1ecdng.\n**Layer** - `overlay` (l\u1edbp ph\u1ee7).\n**Key fields** - `content` (n\u1ed9i dung v\u0103n b\u1ea3n), `animation` (ki\u1ec3u ho\u1ea1t \u1ea3nh), `emphasis` (m\u1ee9c \u0111\u1ed9 nh\u1ea5n m\u1ea1nh).\n**Common animations** - `count_up` (\u0111\u1ebfm l\u00ean), `typing_effect` (hi\u1ec7u \u1ee9ng g\u00f5 ch\u1eef), `flow_chart` (bi\u1ec3u \u0111\u1ed3 d\u00f2ng ch\u1ea3y), `progression_arrow` (m\u0169i t\u00ean ti\u1ebfn tr\u00ecnh), `expansion_flow` (d\u00f2ng ch\u1ea3y m\u1edf r\u1ed9ng), `fade_in_list` (danh s\u00e1ch m\u1edd d\u1ea7n), `pulse` (hi\u1ec7u \u1ee9ng nh\u1ea5p nh\u00e1y).",
        "**Purpose** - S\u1eed d\u1ee5ng c\u00e1c t\u00edn hi\u1ec7u \u00e2m thanh ng\u1eafn \u0111\u1ec3 nh\u1ea5n m\u1ea1nh c\u00e1c kho\u1ea3nh kh\u1eafc quan tr\u1ecdng, t\u1ea1o c\u1ea3m x\u00fac ho\u1eb7c t\u0103ng c\u01b0\u1eddng tr\u1ea3i nghi\u1ec7m ng\u01b0\u1eddi xem.\n**Layer** - `audio` (l\u1edbp \u00e2m thanh).\n**Key field** - `sound` (tham chi\u1ebfu \u0111\u1ebfn ID \u00e2m thanh trong `sfx_catalog.json`).\n**Common sounds** - `transition_rewind` (chuy\u1ec3n c\u1ea3nh tua l\u1ea1i), `whoosh_standard` (ti\u1ebfng v\u00fat ti\u00eau chu\u1ea9n), `ui_pop` (ti\u1ebfng pop giao di\u1ec7n ng\u01b0\u1eddi d\u00f9ng), `money` (ti\u1ec1n), `success` (th\u00e0nh c\u00f4ng), `fire` (l\u1eeda), `achievement` (th\u00e0nh t\u1ef1u), `crash` (va ch\u1ea1m), `money_loss` (m\u1ea5t ti\u1ec1n), `typing` (g\u00f5 ph\u00edm), `confusion` (b\u1ed1i r\u1ed1i), `expansion` (m\u1edf r\u1ed9ng), `emphasis_ding` (ti\u1ebfng ding nh\u1ea5n m\u1ea1nh), `heartbeat_soft` (ti\u1ebfng tim \u0111\u1eadp nh\u1eb9).\n**Defaults** - Ph\u00e1t m\u1ed9t l\u1ea7n v\u1edbi th\u1eddi l\u01b0\u1ee3ng \u0111\u01b0\u1ee3c x\u00e1c \u0111\u1ecbnh b\u1edfi t\u00e0i s\u1ea3n \u00e2m thanh g\u1ed1c.",
        "**Purpose** - T\u1ea1o c\u00e1c chuy\u1ec3n \u0111\u1ed9ng h\u00ecnh \u1ea3nh ho\u1eb7c hi\u1ec7u \u1ee9ng chuy\u1ec3n c\u1ea3nh gi\u1eefa c\u00e1c clip, gi\u00fap video m\u01b0\u1ee3t m\u00e0 v\u00e0 h\u1ea5p d\u1eabn h\u01a1n.\n**Layer** - `transition` (l\u1edbp chuy\u1ec3n c\u1ea3nh).\n**Key fields** - `action` (h\u00e0nh \u0111\u1ed9ng chuy\u1ec3n c\u1ea3nh), `duration` (th\u1eddi l\u01b0\u1ee3ng hi\u1ec7u \u1ee9ng).\n**Common actions** - `zoom_in` (ph\u00f3ng to), `zoom_out` (thu nh\u1ecf), `fade` (m\u1edd d\u1ea7n), `slide_left` (tr\u01b0\u1ee3t sang tr\u00e1i), `slide_right` (tr\u01b0\u1ee3t sang ph\u1ea3i), `push_in` (\u0111\u1ea9y v\u00e0o), `camera_shake` (rung m\u00e1y \u1ea3nh).\n**Defaults** - Th\u1eddi l\u01b0\u1ee3ng t\u1eeb 0.5-2.0 gi\u00e2y tr\u1eeb khi \u0111\u01b0\u1ee3c ghi \u0111\u00e8 b\u1edfi tr\u01b0\u1eddng `duration`.",
        "**Purpose** - S\u1eed d\u1ee5ng c\u00e1c bi\u1ec3u t\u01b0\u1ee3ng \u0111\u1ed3 h\u1ecda t\u0129nh ho\u1eb7c c\u00f3 chuy\u1ec3n \u0111\u1ed9ng t\u1ed1i thi\u1ec3u \u0111\u1ec3 minh h\u1ecda \u00fd t\u01b0\u1edfng, cung c\u1ea5p th\u00f4ng tin nhanh ch\u00f3ng ho\u1eb7c t\u0103ng c\u01b0\u1eddng nh\u1eadn di\u1ec7n th\u01b0\u01a1ng hi\u1ec7u.\n**Layer** - `overlay` (l\u1edbp ph\u1ee7).\n**Key fields** - `content` (n\u1ed9i dung bi\u1ec3u t\u01b0\u1ee3ng, th\u01b0\u1eddng l\u00e0 t\u00ean file ho\u1eb7c ID), `context` (ng\u1eef c\u1ea3nh s\u1eed d\u1ee5ng).",
        "**Purpose** - C\u00e1c t\u00edn hi\u1ec7u c\u1ea5p cao chuy\u00ean bi\u1ec7t \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 gi\u1edbi thi\u1ec7u ng\u01b0\u1eddi n\u00f3i, l\u00e0m n\u1ed5i b\u1eadt c\u00e1c c\u1ed9t m\u1ed1c quan tr\u1ecdng, \u0111\u00e1nh d\u1ea5u c\u00e1c ph\u1ea7n ho\u1eb7c l\u00e0m n\u1ed5i b\u1eadt c\u00e1c t\u1eeb kh\u00f3a. Ch\u00fang xu\u1ea5t hi\u1ec7n tr\u00ean l\u1edbp `main` ho\u1eb7c `overlay`.\n**Usage Notes** - S\u1eed d\u1ee5ng m\u1ed9t c\u00e1ch ti\u1ebft ki\u1ec7m v\u00e0 li\u00ean k\u1ebft ch\u1eb7t ch\u1ebd v\u1edbi c\u00e1c \u0111i\u1ec3m nh\u1ea5n trong c\u00e1c file `videos/*.md` \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o t\u00ednh nh\u1ea5t qu\u00e1n v\u00e0 hi\u1ec7u qu\u1ea3.",
        "`main` - primary camera feed (baseline footage).\n`video` - b-roll replacing or augmenting the main layer.\n`overlay` - text, icons, and animated graphics.\n`audio` - sound effects mixed with narration.\n`transition` - temporary visual effects used between clips.\nRespect layer priority to avoid stacking conflicts; only one dominant element per layer at a time.",
        "Multiple elements can share the same timestamp; treat them as simultaneous but respect layer ordering.\nTransitions (`effect`) should begin before or exactly with the visual/text they introduce.\nUse `style` values to keep branding consistent (default: `highlighted_background` for critical callouts).\nPopulate `context` to support catalog lookups (see [asset_catalogs.md](asset_catalogs.md)).\nRecord `confidence` when available to support downstream thresholding (optional field in `element_schema.json`).",
        "**Full-frame b-roll** \u2013 Every assigned `broll` clip now renders as a full-screen cover beneath overlays. Keep shot selection clear of critical on-screen action, because text overlays will always sit above this layer.\n**Compressed highlight copy** \u2013 Generated `noteBox`/`text_overlay` content must be distilled to 1\u20133 uppercase keywords (primary nouns/verbs). Dual-column highlights should keep each side within this limit.\n**Staggered overlays** \u2013 When both left/right supporting texts are present, the left column should appear a fraction earlier (\u22480.2 s) to mirror the pacing demonstrated in Video 1."
      ],
      "metadata": {}
    },
    {
      "identifier": "element_schema.md",
      "title": "Element Schema",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\element_schema.md",
      "headings": [
        [
          "Element Schema (element_schema.json)",
          1
        ],
        [
          "Schema Overview",
          2
        ],
        [
          "Key Properties and Their Constraints",
          2
        ],
        [
          "Required Fields for All Elements",
          3
        ],
        [
          "Optional Fields",
          3
        ],
        [
          "Type-Specific Requirements (allOf)",
          2
        ]
      ],
      "sections": [
        "This document describes the JSON schema used to define the structure and constraints for all timeline elements generated by the AI planning system. This schema is critical for ensuring consistency, validity, and interoperability of the AI's output with the video rendering pipeline.",
        "The `element_schema.json` file enforces the following key aspects for each video element:\n**`timestamp`**: The exact time in seconds from the video's start when the element should appear. Must be a non-negative number.\n**`duration`**: The length of the element in seconds. Must be a positive number.\n**`type`**: The family or category of the element (e.g., `broll`, `text_overlay`, `sound_effect`). This field is crucial for determining which other properties are required.\n**`layer`**: The rendering layer in the compositing stack where the element will be placed (e.g., `main`, `video`, `overlay`, `audio`, `transition`). This ensures proper visual and auditory hierarchy.",
        "",
        "`timestamp` (number): Th\u1eddi gian xu\u1ea5t hi\u1ec7n c\u1ee7a ph\u1ea7n t\u1eed t\u00ednh b\u1eb1ng gi\u00e2y k\u1ec3 t\u1eeb khi video b\u1eaft \u0111\u1ea7u. Ph\u1ea3i l\u00e0 s\u1ed1 kh\u00f4ng \u00e2m.\n`type` (string): \u0110\u1ecbnh danh lo\u1ea1i ph\u1ea7n t\u1eed (v\u00ed d\u1ee5: `broll`, `text_overlay`, `sound_effect`).\n`layer` (string): L\u1edbp hi\u1ec3n th\u1ecb trong ng\u0103n x\u1ebfp t\u1ed5ng h\u1ee3p.",
        "`duration` (number): \u0110\u1ed9 d\u00e0i c\u1ee7a ph\u1ea7n t\u1eed t\u00ednh b\u1eb1ng gi\u00e2y. Ph\u1ea3i l\u00e0 s\u1ed1 d\u01b0\u01a1ng.\n`description` (string, max 280 characters): M\u00f4 t\u1ea3 d\u1ec5 \u0111\u1ecdc cho vi\u1ec7c l\u1ef1a ch\u1ecdn t\u00e0i s\u1ea3n (b-roll/nh\u1ea5n m\u1ea1nh).\n`content` (string or object, max 180 characters for string, max 120 characters for object properties): N\u1ed9i dung hi\u1ec3n th\u1ecb tr\u00ean m\u00e0n h\u00ecnh ho\u1eb7c t\u1ea3i tr\u1ecdng c\u00f3 c\u1ea5u tr\u00fac cho c\u00e1c ph\u1ea7n t\u1eed v\u0103n b\u1ea3n.\nIf string: On-screen copy.\nIf object: Structured layout for lists or split overlays.\n`style` (string): Bi\u1ebfn th\u1ec3 ki\u1ec3u v\u0103n b\u1ea3n ho\u1eb7c \u0111\u1ed3 h\u1ecda (e.g., `highlighted_background`, `clean_minimal`).\n`animation` (string): Thi\u1ebft l\u1eadp s\u1eb5n ho\u1ea1t \u1ea3nh \u00e1p d\u1ee5ng cho v\u0103n b\u1ea3n ho\u1eb7c ph\u1ea7n t\u1eed \u0111\u1ed3 h\u1ecda (e.g., `fade_in`, `count_up`).\n`sound` (string): \u0110\u1ecbnh danh t\u00e0i s\u1ea3n hi\u1ec7u \u1ee9ng \u00e2m thanh (e.g., `transition_rewind`, `ui_pop`).\n`action` (string): H\u01b0\u1edbng d\u1eabn chuy\u1ec3n c\u1ea3nh ho\u1eb7c chuy\u1ec3n \u0111\u1ed9ng cho c\u00e1c hi\u1ec7u \u1ee9ng (e.g., `zoom_in`, `fade`).\n`layer_priority` (integer, 0-5): \u01afu ti\u00ean l\u1edbp t\u00f9y ch\u1ecdn cho vi\u1ec7c t\u1ed5ng h\u1ee3p khi nhi\u1ec1u ph\u1ea7n t\u1eed l\u1edbp ph\u1ee7 x\u1ebfp ch\u1ed3ng l\u00ean nhau.\n`confidence` (number, 0-1): \u0110i\u1ec3m tin c\u1eady c\u1ee7a m\u00f4 h\u00ecnh cho ph\u1ea7n t\u1eed.\n`context` (string, max 200 characters): Gi\u1ea3i th\u00edch ng\u1eafn g\u1ecdn v\u1ec1 \u00fd \u0111\u1ecbnh t\u01b0\u1eddng thu\u1eadt (ph\u1ea3n \u00e1nh c\u00e1c ch\u00fa th\u00edch JSON).\n`tags` (array of strings, max 8 items, each max 40 characters, unique): T\u1eadp h\u1ee3p c\u00e1c th\u1ebb ng\u1eef ngh\u0129a t\u00f9y ch\u1ecdn \u0111\u01b0\u1ee3c s\u1eed d\u1ee5ng \u0111\u1ec3 kh\u1edbp n\u1ed1i.\n`constraints` (object): C\u00e1c \u0111i\u1ec1u ki\u1ec7n c\u1ee5 th\u1ec3 c\u1ee7a ph\u1ea7n t\u1eed \u0111\u01b0\u1ee3c th\u1ef1c thi trong qu\u00e1 tr\u00ecnh x\u00e1c th\u1ef1c.",
        "The schema uses `allOf` to define conditional requirements based on the `type` of the element:\n**`broll`**:\nRequires `description`.\n`layer` must be `video`.\n**`text_overlay`, `text_animation`, `icon`, `section_header`, `emphasis`**:\nRequires `content`.\n`layer` must be `overlay`.\n**`sound_effect`**:\nRequires `sound`.\n`layer` must be `audio`.\n**`effect`**:\nRequires `action` and `duration`.\n`layer` must be `transition`.\n**`speaker_intro`, `achievement_highlight`**:\n`layer` must be `main`.\nThis schema ensures that all AI-generated video plan elements adhere to a strict, well-defined structure, facilitating robust validation and seamless integration into the video production workflow."
      ],
      "metadata": {}
    },
    {
      "identifier": "examples\\patterns.md",
      "title": "Patterns",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\examples\\patterns.md",
      "headings": [
        [
          "Editing Patterns",
          1
        ],
        [
          "Video 1 - How I Would Learn Digital Marketing",
          2
        ],
        [
          "Introduction & Hook",
          3
        ],
        [
          "Three-Part Learning Framework",
          3
        ],
        [
          "Practice Principles",
          3
        ],
        [
          "Career Path Discussion",
          3
        ],
        [
          "Video 2 - Digital Marketing 101",
          2
        ],
        [
          "Foundational Concepts",
          3
        ],
        [
          "Channel Definitions",
          3
        ],
        [
          "Digital vs. Traditional Marketing",
          3
        ],
        [
          "B2B vs. B2C",
          3
        ],
        [
          "Feature vs. Benefit",
          3
        ],
        [
          "General Principles for Pattern Application",
          2
        ],
        [
          "Purpose",
          2
        ],
        [
          "Structure",
          2
        ],
        [
          "Usage",
          2
        ]
      ],
      "sections": [
        "This document provides qualitative descriptions and examples of common editing patterns used in the video automation pipeline. These patterns serve as concrete exemplars for the AI model, demonstrating how different video elements should be combined and sequenced to achieve specific narrative and visual effects. For machine-readable, structured examples, refer to `patterns.json`.",
        "",
        "**Pattern**: Speaker intro with a bold, engaging question.\n**Elements**: `speaker_intro` (main layer), `text_overlay` (overlay layer) with `bold_emphasis` style.\n**Rationale**: Immediately captures viewer attention and sets the stage for the video's core topic.",
        "**Pattern**: Progressive list reveal for a multi-stage framework.\n**Elements**: Series of `text_overlay` elements with `fade_in_list` animation, each adding a new point to the previous one.\n**Rationale**: Visually reinforces the structured learning path, making it easy for viewers to follow.",
        "**Pattern**: Iconography with brief text overlays for key principles.\n**Elements**: `icon` (overlay layer) with relevant `content` (e.g., lightbulb for \"innovation\"), accompanied by `text_overlay` with `clean_minimal` style.\n**Rationale**: Provides quick visual cues for abstract concepts, enhancing comprehension and retention.",
        "**Pattern**: B-roll footage illustrating career growth or industry trends.\n**Elements**: `broll` (video layer) with `description` matching the spoken content (e.g., \"modern office\", \"digital network\").\n**Rationale**: Breaks up speaker footage, adds visual interest, and metaphorically supports the narrative.",
        "",
        "**Pattern**: Highlighted definitions with `highlighted_background` style.\n**Elements**: `text_overlay` (overlay layer) with `highlighted_background` style for key terms and their definitions.\n**Rationale**: Ensures critical vocabulary is clearly presented and easily digestible.",
        "**Pattern**: Split-column text overlay for comparing different channels.\n**Elements**: `text_overlay` (overlay layer) with `split_column` style, presenting two or more channels side-by-side.\n**Rationale**: Facilitates direct comparison and highlights distinctions between various digital marketing channels.",
        "**Pattern**: Animated flow chart or progression arrow for comparative analysis.\n**Elements**: `text_animation` (overlay layer) with `flow_chart` or `progression_arrow` animation, illustrating the differences and evolution.\n**Rationale**: Visually explains complex comparisons and shows relationships between concepts.",
        "**Pattern**: Callout box with concise summaries for business models.\n**Elements**: `text_overlay` (overlay layer) with `callout_box` style, providing bullet points or short descriptions for each model.\n**Rationale**: Offers a clear, encapsulated summary of distinct business approaches.",
        "**Pattern**: Icon effect with a subtle sound cue for emphasis.\n**Elements**: `icon` (overlay layer) appearing with a `ui_pop` `sound_effect` (audio layer) when a feature or benefit is introduced.\n**Rationale**: Draws attention to the distinction and reinforces the learning point with an auditory cue.",
        "**Contextual Relevance**: Always ensure the chosen pattern aligns with the narrative intent and emotional tone of the spoken content.\n**Pacing**: Adjust the duration and animation speed of elements to match the speaker's pace and the overall rhythm of the video.\n**Clarity**: Prioritize clear communication. Overlays should be concise, and visuals should directly support the message without distraction.\n**Brand Consistency**: Adhere to established brand guidelines for styles, colors, and animations.\n**Layer Management**: Avoid visual clutter by respecting the layer stack hierarchy and ensuring elements do not overlap unnecessarily.\n**Sound Reinforcement**: Use sound effects judiciously to enhance emphasis and transitions, not to overwhelm the viewer.",
        "The `patterns.json` file provides machine-readable examples that complement the qualitative descriptions in `patterns.md`. It helps the AI model learn:\n**Correct sequencing**: How elements like `text_overlay`, `broll`, and `sound_effect` should follow each other.\n**Contextual application**: When to use specific styles, animations, or sound effects based on the narrative context.\n**Constraint adherence**: Examples that demonstrate compliance with rules defined in `element_schema.json` and `motion_rules.json`.",
        "The `patterns.json` file is an array of objects, where each object represents a specific editing pattern. Each pattern typically includes:\n**`name`**: A descriptive name for the pattern.\n**`description`**: A brief explanation of the pattern's intent and usage.\n**`elements`**: An array of video elements, each conforming to the `element_schema.json`, demonstrating the pattern. These elements include `timestamp`, `type`, `layer`, and other relevant properties.\n**`notes`**: Additional qualitative notes or rationale for the pattern.",
        "**Training**: Used as structured training data to teach the AI model how to generate valid and effective video plans.\n**Validation**: Provides concrete test cases for validating the AI's output against known good examples.\n**Debugging**: Helps in understanding and debugging unexpected behaviors in the AI's plan generation by comparing outputs to these reference patterns.\nRefer to `knowledge-base/examples/patterns.md` for qualitative descriptions and further context on these editing patterns."
      ],
      "metadata": {}
    },
    {
      "identifier": "glossary.md",
      "title": "Glossary",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\glossary.md",
      "headings": [
        [
          "Glossary",
          1
        ]
      ],
      "sections": [
        "This document provides a comprehensive glossary of key terms and concepts used throughout the AI video automation project. Definitions are grounded in the reference transcripts, training documentation, and general machine learning terminology. Understanding these terms is essential for navigating the project's codebase and documentation effectively.\nShort definitions grounded in the reference transcripts and training documentation.\n**Digital marketing** - marketing activities executed through digital channels (SEO, social media, PPC, email, websites). *Related:* Traditional marketing.\n**Traditional marketing** - offline channels such as print, radio, direct mail; contrasted with digital to highlight reach and measurability differences. *See also:* [planning_guidelines.md](planning_guidelines.md#narrative-alignment).\n**SEO (Search Engine Optimization)** - practice of improving organic visibility; central focus of the speaker's career pivot in Video 1. *Related:* Search marketing.\n**B-roll** - supplemental footage used to visualise or emphasise narration. *See also:* [asset_catalogs.md](asset_catalogs.md#catalog-overview).\n**Callout / Highlight** - on-screen emphasis for key phrases, statistics, or warnings, typically rendered as `text_overlay`.\n**Framework** - structured list or set of stages (for example, three-part learning model, four practice principles); often represented with progressive overlays.\n**Stage 1 / 2 / 3 (Learning)** - understand fundamentals -> connect fundamentals -> practise execution (Video 1).\n**Product marketing** - showcasing features and tangible benefits of a physical good.\n**Service marketing** - selling the outcome or end state (experience, trust, transformation) rather than the service mechanics.\n**B2B (Business to Business)** - companies selling to other businesses; longer cycles, committee decisions.\n**B2C (Business to Consumer)** - companies selling directly to consumers; faster decisions, emotion-driven.\n**Feature vs Benefit** - feature describes what something is; benefit explains the value it delivers (Video 2 pen example).\n**Trust signals** - elements that reinforce credibility (awards, experience, social proof).\n**Motion cue** - visual effect (zoom, slide) signalling a narrative shift or emphasis. *See also:* Motion rules in `motion_rules.json`.\n**Embedding** - numeric vector representing semantic meaning of text or assets, used for similarity search and modelling (for example, Sentence-BERT). *Related:* Feature engineering.\n**Word2Vec / GloVe / Sentence-BERT** - families of embedding models; Sentence-BERT produces sentence-level vectors well suited for transcript windows.\n**One-hot encoding** - representation where each category maps to a unique vector with a single 1 and the rest 0; used for element types and styles.\n**Regression head** - model component predicting continuous values (for example, `timestamp`, `duration`). *See:* `training_pipeline.md`.\n**Multi-label classification** - predicting multiple boolean outcomes simultaneously (for example, presence of several element families in a window).\n**MAE (Mean Absolute Error)** - evaluation metric for regression measuring average absolute difference between predicted and true values.\n**F1 score** - harmonic mean of precision and recall; used to assess classification performance.\n**BLEU / ROUGE** - text generation metrics comparing model output to reference wording; apply to overlay copy evaluation.\n**Early stopping** - training technique that halts optimisation when validation performance stops improving to avoid overfitting.\n**Curriculum learning** - training strategy that teaches simpler tasks before harder ones (for example, predict type before content).\n**Confidence score** - probability estimate output by the model indicating reliability of a prediction; captured in `element_schema.json`.\n**Layer stack** - render order from `main` -> `video` -> `overlay` -> `audio` -> `transition`; detailed in [element_definitions.md](element_definitions.md#layer-stack).\n**Context tag** - short descriptive string indicating narrative intent (for example, \"mistake warning\"); used to query asset catalogs and maintain coherence."
      ],
      "metadata": {}
    },
    {
      "identifier": "planning_guidelines.md",
      "title": "Planning Guidelines",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\planning_guidelines.md",
      "headings": [
        [
          "Planning Guidelines",
          1
        ],
        [
          "Narrative Alignment",
          2
        ],
        [
          "B-Roll Selection",
          2
        ],
        [
          "Text & Animated Overlays",
          2
        ],
        [
          "Sound Effects",
          2
        ],
        [
          "Motion & Transitions",
          2
        ],
        [
          "Layer & Timing Hygiene",
          2
        ],
        [
          "Content Consistency",
          2
        ]
      ],
      "sections": [
        "This document outlines the operational rules and best practices for proposing timeline elements that align with the reference videos. These guidelines are crucial for ensuring that AI-generated video plans are consistent, high-quality, and adhere to established production standards. Cross-reference [element_definitions.md](element_definitions.md) for detailed layer behavior and [quality_criteria.md](quality_criteria.md) for validation thresholds.",
        "Anchor every element to a transcript clause; avoid floating overlays with no spoken support. *Rationale:* Maintains coherence with dialogue and prevents disjointed visuals.\nTrack signal phrases (\"Part 1\", \"Stage 2\", \"Option 3\", \"Here's why\") to justify section headers or text overlays. *Rationale:* Reinforces structural beats described in [videos/video1_outline.md](videos/video1_outline.md) and [videos/video2_outline.md](videos/video2_outline.md).\nAlign stories and analogies with metaphorical b-roll using `context` hints or tag matches from [asset_catalogs.md](asset_catalogs.md). *Rationale:* Visualises abstract concepts for faster comprehension.",
        "Pick b-roll that literalises or metaphorically echoes the spoken idea (for example, trash bin for \"mistakes\", instruments for \"learning analogies\", skyline for \"market scale\"). *Rationale:* Supports narrative cues in transcripts.\nMatch tone and pacing: fast cuts for energetic lists, steadier shots for reflective segments. *Rationale:* Mood tags in `broll_catalog.json` help maintain emotional alignment.\nLet each clip play until another `video` layer element arrives; smooth abrupt switches with `effect` actions defined in [element_schema.json](element_schema.json). *Rationale:* Avoids jarring cuts while respecting defaults in [element_definitions.md](element_definitions.md#element-families).",
        "Use `highlighted_background` as the default for key facts, comparisons, and definitions. *Rationale:* Brand-consistent and legible (see `style` enum in `element_schema.json`).\nBuild progressive lists for frameworks; each new point appends to the previous overlay. *Rationale:* Mirrors positive examples in [examples/patterns.md](examples/patterns.md#video-1---how-i-would-learn-digital-marketing).\nApply `text_animation` presets when narration references numbers climbing (`count_up`) or typing/flow (`typing_effect`, `flow_chart`). *Rationale:* Motion choices should support narrative metaphors; guardrails defined in `motion_rules.json`.\nKeep copy concise and faithful to the transcript; default to title case for readability. *Rationale:* Preserves voice and aligns with guidance in [glossary.md](glossary.md).\nSurface highlight keywords as 1\u20132 word noun or verb phrases that retain meaning together; drop conversational fillers (`uh`, `oh`, `you know`) before publishing. *Rationale:* Keeps on-screen knowledge base text signal-rich and purposeful.",
        "Pair new terms or section changes with subtle SFX (`ui_pop`, `whoosh_standard`). *Rationale:* Audio cues boost recall and correspond to assets in `sfx_catalog.json`.\nReserve `money`, `success`, or `achievement` sounds for monetary claims or milestones. *Rationale:* Prevents semantic drift and keeps the acoustic palette purposeful.\nUse `typing` sounds only when animations or narration mention writing or typing. *Rationale:* Maintains cohesive audiovisual storytelling.",
        "Trigger `zoom_in` on turning points or emphasised statements (\"this is the key\", \"here's the mistake\"). *Rationale:* Heightens focus; validated by examples in [examples/patterns.json](examples/patterns.json).\nDeploy `zoom_out` to release tension or provide wider context after a focal point. *Rationale:* Restores viewer orientation.\nSpace identical effects by at least 0.5 s unless narrative urgency demands otherwise. *Rationale:* Enforced by `motion_rules.json`; avoids viewer fatigue (see negative cases in `patterns.json`).",
        "Do not overlap full-screen overlays at the same timestamp; offset by at least 0.3 s or merge copy. *Rationale:* Respects the stack hierarchy defined in [element_definitions.md](element_definitions.md#layer-stack).\nWhen the `video` layer is active (b-roll), overlays may occupy full width; otherwise keep margins to protect speaker visibility. *Rationale:* Preserves essential facial expressions.\nEnd SFX before the next major beat and cap overlay visibility at 6-8 s unless the segment is static. *Rationale:* Aligns with [quality_criteria.md](quality_criteria.md#timing) to prevent lingering elements.",
        "Use canonical terminology (\"digital marketing\", \"traditional marketing\", \"B2B/B2C\", \"feature vs benefit\"). *Rationale:* Vocabulary centralised in [glossary.md](glossary.md) ensures consistent messaging.\nKeep tone authoritative, instructional, and encouraging as reflected in both transcripts. *Rationale:* Matches target audience described in video outlines.\nMaintain chronological order in lists (for example, \"Stage 1 -> Stage 2 -> Stage 3\"). *Rationale:* Prevents cognitive dissonance and supports pedagogy."
      ],
      "metadata": {}
    },
    {
      "identifier": "quality_criteria.md",
      "title": "Quality Criteria",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\quality_criteria.md",
      "headings": [
        [
          "Quality Criteria",
          1
        ],
        [
          "Timing",
          2
        ],
        [
          "Coverage",
          2
        ],
        [
          "Layer Integrity",
          2
        ],
        [
          "Content Accuracy",
          2
        ],
        [
          "Style Consistency",
          2
        ],
        [
          "Review Workflow",
          2
        ]
      ],
      "sections": [
        "This document defines the benchmarks and standards used for reviewing both AI model outputs and human-labelled video plans. Adhering to these criteria ensures the consistency, accuracy, and overall quality of the generated video content, facilitating effective evaluation and continuous improvement of the AI system.\nBenchmarks for reviewing model outputs and human-labelled plans.",
        "**Timestamp error** <= 0.5 s for overlays and SFX, <= 1.0 s for b-roll and transitions.\n**Duration consistency** - no element persists past the next conflicting cue; default to metadata rules in `element_definitions.md`.",
        "Every major section (see `videos/*.md`) contains at least one supporting visual element.\nNo unaddressed transcript peaks: stories, statistics, frameworks, and comparisons must trigger at least a text overlay or b-roll.",
        "Only one element per layer at any instant (exceptions: audio layer can stack ambience plus SFX if mix-tested).\nTransitions do not collide with overlays unless intentionally coordinated.",
        "On-screen text mirrors transcript wording or summarises it accurately without introducing new facts.\nB-roll descriptions are actionable for editors (clear subject, action, mood).\nSound choices reinforce the message rather than distract.",
        "`highlighted_background` used for high-importance text across videos unless brand guidelines dictate otherwise.\nAnimation choices match narrative intent (for example, `typing_effect` only when typing is implied).\nColour, tone, and energy remain aligned with the source videos' instructional style.",
        "Automated checks: compare predicted elements to ground truth with metrics (F1, MAE).\nHuman review: run through transcripts while watching the plan, verifying that each cue feels natural.\nRegression guardrail: maintain a curated library of \"golden\" plan outputs; new models must meet or exceed their scores."
      ],
      "metadata": {}
    },
    {
      "identifier": "README.md",
      "title": "Readme",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\README.md",
      "headings": [
        [
          "AI Planning Knowledge Base",
          1
        ],
        [
          "Scope",
          2
        ],
        [
          "Directory Map",
          2
        ],
        [
          "Usage Guidance",
          2
        ]
      ],
      "sections": [
        "This repository serves as the central knowledge base for the AI-driven video plan generation pipeline. It contains all essential reference materials, including rules, definitions, workflows, quality criteria, examples, and asset references. This knowledge base is critical for supporting the training, inference, and evaluation phases of the AI model, ensuring that generated video plans are accurate, consistent, and aligned with production standards.\nCentral repository of reference materials that support training, inference, and evaluation of the video plan-generation pipeline.",
        "Consolidates rules, definitions, workflows, criteria, examples, and asset references derived from:\n`AI_Training_Plan.md`\n`transcript_video_1.txt` / `video1.json`\n`transcript_video_2.txt` / `video2.json`\nAsset catalogs under `assets/`\nGoal: guide the model to place highlights, b-roll, sound effects, overlays, and motion cues with high accuracy and narrative relevance.",
        "`data_sources.md` - provenance and key takeaways from transcripts, timelines, and catalogs.\n`training_pipeline.md` - end-to-end preparation and modelling process.\n`element_definitions.md` - glossary for element types, layers, and default behaviours.\n`element_schema.json` - machine-readable schema describing required fields, enumerations, and validation constraints.\n`planning_guidelines.md` - actionable rules for proposing timeline elements with cross-references.\n`quality_criteria.md` - success metrics and acceptance checkpoints.\n`glossary.md` - domain terminology used across the knowledge base.\n`asset_catalogs.md` - how to incorporate `broll`, `sfx`, `motion`, and context catalogs into modelling.\n`examples/` - qualitative (`patterns.md`) and structured (`patterns.json`) editing exemplars.\n`videos/` - narrative blueprints for each reference video (summary, audience, themes, cue suggestions).\n`CHANGELOG.md` - tracked updates to maintain version history.",
        "Review `data_sources.md` to understand raw inputs and supporting catalogs.\nAlign feature engineering and targets using `training_pipeline.md`, `element_definitions.md`, and `element_schema.json`.\nDuring plan generation, enforce `planning_guidelines.md` and validate against `quality_criteria.md`.\nLeverage `asset_catalogs.md` alongside the JSON catalogs to ensure selected assets exist and honour motion rules.\nConsult `videos/` and `examples/` for grounded samples (positive and negative) before crafting prompts, labels, or rule-based validators.\nLog any documentation changes in `CHANGELOG.md` so training runs can reference the correct knowledge base version."
      ],
      "metadata": {}
    },
    {
      "identifier": "training_pipeline.md",
      "title": "Training Pipeline",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\training_pipeline.md",
      "headings": [
        [
          "Training Pipeline Blueprint",
          1
        ],
        [
          "1. Audit Existing Data & Targets",
          2
        ],
        [
          "2. Preprocess & Align",
          2
        ],
        [
          "3. Feature Engineering",
          2
        ],
        [
          "4. Model Strategy",
          2
        ],
        [
          "5. Training Routine",
          2
        ],
        [
          "6. Evaluation",
          2
        ],
        [
          "7. Deployment Checklist",
          2
        ],
        [
          "8. Maintenance Cadence",
          2
        ],
        [
          "9. Risk Controls",
          2
        ]
      ],
      "sections": [
        "This document serves as the authoritative blueprint for the AI video plan generation training pipeline. It details the end-to-end process, from data preparation and feature engineering to model strategy, training routines, evaluation, and deployment. This blueprint is derived from the `AI_Training_Plan.md` (Vietnamese source) and should be used as the primary reference when preparing datasets, developing new models, or evolving the existing model stack.\nDerived from `AI_Training_Plan.md` (Vietnamese source). Use this as the authoritative workflow when preparing datasets or evolving the model stack.",
        "Understand transcript structure, narration pace, and how timeline annotations map to speech.\nCatalogue every element attribute that must be predicted: `timestamp`, `duration`, `type`, `layer`, `content/description`, `style`, `animation`, `sound`, `action`, optional `context` and `confidence` (see [element_schema.json](element_schema.json)).\nConfirm ingestion coverage for both transcripts and JSON timelines; flag missing sections or inconsistent timestamps.",
        "Merge transcript text with timeline entries by timestamp, producing windows (5-10 seconds) that give sufficient context.\nNormalize timestamps to seconds for easier maths and modelling.\nSegment transcripts into sentences or clauses; tokenise and build embeddings (Sentence-BERT or equivalent).\nEncode video elements: one-hot for categorical fields, embeddings for text-heavy attributes (`description`, `content`); ensure categorical vocab matches [element_schema.json](element_schema.json).",
        "Transcript features: semantic vectors, sentence length, relative position within the video, keyword flags (for example, \"Part 1\", \"mistake\", \"option\").\nAudio/tempo proxies: estimate speaking rate via word counts per window.\nTimeline context: distance to previous/next elements, element type history, context tags (aligned to `context_rules.json`).\nStyle cues: reuse `context` labels to signal metaphors, comparisons, or emphasis needs.\nAsset compatibility: embed catalog metadata (for example, `tags`, `mood`, `intensity`) from `broll_catalog.json` and `sfx_catalog.json` for recommendation scoring.",
        "Treat timestamp and duration predictions as regression; element presence and type as multi-label or multi-class classification.\nConsider hierarchical modelling: first detect whether an element occurs, then specialise by element family.\nExplore sequence-to-sequence or encoder-decoder approaches for generating ordered element lists.\nReserve capacity for generative text (for example, overlay copy) via template libraries or conditional generation models.",
        "Split data by video to avoid leakage (train on one video, validate on another, rotate as more data arrives).\nUse curriculum: start with type/layer predictions, then add auxiliary heads (content, style).\nApply class balancing (oversampling rare elements like `achievement_highlight`).\nMonitor convergence per head; early-stop if accuracy plateaus but loss diverges.",
        "Quantitative: accuracy/F1 for type classification, MAE for timestamps, BLEU/ROUGE for generated text.\nQualitative: human review against `quality_criteria.md` with focus on narrative fit and layer conflicts.\nStress tests: long speaking segments without elements, rapid-fire sections with many overlays, sections requiring metaphors.",
        "Package preprocessing scripts, model weights, `element_schema.json`, and inference pipeline.\nProvide fallbacks when confidence is low (for example, default overlays or prompts for manual review).\nLog predictions with timestamps and context for downstream auditing.",
        "Quarterly data refresh to incorporate new annotated videos.\nMonthly error analysis session targeting repeated failure modes (mis-timed SFX, incorrect layer stacking).\nCapture feedback from editors to expand context tags and example catalogues.",
        "Mitigate noisy timestamps by smoothing predictions and enforcing minimum separation thresholds defined in `motion_rules.json`.\nPrevent style drift by constraining `style` predictions to allowed set per brand guide.\nDocument assumptions about transcript accuracy; include fallbacks when speech deviates from script."
      ],
      "metadata": {}
    },
    {
      "identifier": "videos\\video1_outline.md",
      "title": "Video1 Outline",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\videos\\video1_outline.md",
      "headings": [
        [
          "Video 1 Narrative Blueprint",
          1
        ],
        [
          "Recurring Cues",
          3
        ]
      ],
      "sections": [
        "This document provides a detailed narrative blueprint for \"Video 1: How I Would Learn Digital Marketing (If I Could Start Over)\". It outlines the video's core elements, including its title, summary, target audience, tone, pacing, and primary themes. This blueprint serves as a guide for AI model training and video plan generation, ensuring that the output aligns with the original video's intent and structure.\n**Title:** *How I Would Learn Digital Marketing (If I Could Start Over)*\n**Summary:** Speaker recounts a 14-year marketing journey, distilling mistakes, learning frameworks, and practice principles into a repeatable roadmap.\n**Target audience:** Early-career marketers who need a structured plan to specialise and grow credibility.\n**Tone and pacing:** Authoritative yet conversational; alternates between reflective storytelling and energetic calls to action.\n**Primary themes:** Focus, structured learning, disciplined practice, career path selection, credibility building.\nSection\nTimestamp\nNarrative focus\nElement opportunities\nEmotional tone\nIntroduction\n0:00-0:35\nEstablishes career credibility and achievements.\n`speaker_intro`, business montage b-roll, magazine overlays, `achievement_highlight` for \"Top 1%\".\nConfident, aspirational\nPart 1: Choose One Area\n0:35-2:02\nShares early missteps and lesson on focus.\nOverlay \"Choose One Area\", b-roll metaphors for distractions, `money_loss` SFX on wasted spend moments.\nCautionary, reflective\nPart 2: Commit to Learning\n2:02-4:24\nIntroduces three-stage learning framework.\nProgressive list overlays, `flow_chart` or `typing_effect` animations, instrument/cooking b-roll metaphors.\nInstructive, structured\nPart 3: Commit to Practicing\n4:24-10:02\nPractical execution guide: cut content, prioritise, agency work, avoid shortcuts, network.\nExpanding checklist overlays, `typing` SFX, agency/workspace b-roll, `zoom_in` on cautionary story beats.\nMotivational, urgent\nCareer Paths\n10:02-11:51\nPresents options: stay generalist, niche down, expand skills.\nComparison table overlay, workplace b-roll varieties, gentle transition effects between options.\nStrategic, optimistic\nConclusion and CTA\n11:51-12:53\nSummarises journey, invites viewers to SEO course.\nClosing overlay \"Start Your SEO Journey\", upbeat b-roll, `success` or `achievement` SFX.\nEncouraging, forward-looking",
        "Lists expand rather than reset, so design overlays that append items sequentially.\nCredibility signals (\"Forbes\", \"Inc\", \"Top 1%\") deserve combined overlay plus b-roll emphasis.\nFailure stories lean on darker-toned visuals and restrained SFX; resolve with lighter shots as tone lifts.\nRelationship-building advice pairs well with collaborative or networking imagery."
      ],
      "metadata": {}
    },
    {
      "identifier": "videos\\video2_outline.md",
      "title": "Video2 Outline",
      "doc_type": "markdown",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\videos\\video2_outline.md",
      "headings": [
        [
          "Video 2 Narrative Blueprint",
          1
        ],
        [
          "Recurring Cues",
          3
        ]
      ],
      "sections": [
        "This document provides a detailed narrative blueprint for \"Video 2: Digital Marketing 101 (A Beginner's Guide to Marketing)\". It outlines the video's core elements, including its title, summary, target audience, tone, pacing, and primary themes. This blueprint serves as a guide for AI model training and video plan generation, ensuring that the output aligns with the original video's intent and structure.\n**Title:** *Digital Marketing 101 (A Beginner's Guide to Marketing)*\n**Summary:** Breaks down foundational marketing concepts, contrasting strategies, channels, and audience types to equip beginners with a holistic view.\n**Target audience:** New or transitioning marketers seeking clarity on terminology, strategy-versus-tactics differentiation, and channel selection.\n**Tone and pacing:** Energetic and instructive; balances conceptual explanation with actionable tips.\n**Primary themes:** Fundamentals first, strategy vs tactics, channel comparisons, intent-driven marketing, audience segmentation.\nSection\nTimestamp\nNarrative focus\nElement opportunities\nEmotional tone\nIntroduction\n0:00-0:30\nSets promise: become a better digital marketer.\nTitle overlay \"Digital Marketing 101\", subtitle overlay with `highlighted_background`, upbeat intro sting.\nMotivational\nDigital vs Traditional\n0:37-1:40\nDefines digital marketing and contrasts with traditional media.\nComparison overlays, `whoosh_standard` SFX, split b-roll (online vs offline).\nExplanatory\nChannel Examples\n1:02-3:10\nLists core channels: SEO, social media, PPC, email, web optimisation.\nTerm overlays with `ui_pop`, iconography, quick cutaway b-roll.\nInformative\nFundamentals over Tactics\n3:33-4:05\nEmphasises understanding buyer behaviour beyond tools.\nOverlay \"Master Fundamentals Before Tools\", reflective b-roll, soft `zoom_in`.\nReflective\nStrategy vs Tactics and Core Four\n4:07-7:35\nDifferentiates strategy and tactics; introduces Model, Market, Message, Media.\nProgressive overlays, `flow_chart` animation, category-specific b-roll.\nStructured, didactic\nTactics and Scheduling\n7:36-8:20\nApplies ideas to posting cadence and content types.\nChecklist overlay, subtle `typing_effect`, workflow visuals.\nPractical\nOrganic vs Paid\n8:31-9:20\nContrasts organic content with paid promotion.\nSplit layout overlay, icons, `fade_in_list`, balanced SFX.\nComparative\nDirect Response vs Brand Awareness\n10:20-11:55\nClarifies short-term vs long-term marketing goals.\nDual-column overlay, `zoom_in` warning on \"wrong tool\", case-study b-roll.\nCautionary\nSearch vs Discovery\n12:15-14:05\nHighlights platform intent differences.\nOverlay \"Intent = Key\", platform icons, measured `zoom_in`.\nAnalytical\nProducts vs Services\n14:12-16:05\nExplains tangible vs intangible marketing focus.\nFeature vs Benefit overlay, `ui_pop`, pen demonstration b-roll, service outcome imagery.\nIllustrative\nB2B vs B2C\n16:26-17:11\nDifferentiates business vs consumer audiences.\nComparison overlay with `fade_in_list`, `whoosh_standard`, business/consumer visuals.\nClarifying\nOutro and CTA\n17:03-17:11\nDirects viewers to deeper B2B vs B2C content.\nCTA overlay \"Watch B2B vs B2C Breakdown\", `emphasis_ding`, end-card b-roll.\nEncouraging",
        "`highlighted_background` remains the default text treatment throughout; maintain consistency unless context demands variation.\nComparisons thrive on side-by-side overlays (for example, \"Feature | Benefit\", \"Organic | Paid\"); ensure columns stay balanced.\nIntroduce new terminology with matching SFX and maintain momentum with responsive motion cues.\nReserve zoom chains for genuine emphasis; interleave with fades or slides to give viewers recovery time."
      ],
      "metadata": {}
    }
  ],
  "json": [
    {
      "identifier": "element_schema.json",
      "title": "Element Schema",
      "doc_type": "json",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\element_schema.json",
      "headings": [],
      "sections": [],
      "metadata": {
        "hash": "48dc8e5631b7262bfd7031845e70971fadd61f5cf2d7100203d56da6a607d6f4"
      }
    },
    {
      "identifier": "examples\\patterns.json",
      "title": "Patterns",
      "doc_type": "json",
      "path": "D:\\Projects\\Crownmercado\\video-automation\\knowledge-base\\examples\\patterns.json",
      "headings": [],
      "sections": [],
      "metadata": {
        "hash": "4eaa1898e934e26aa5b9fdddff580c001f6903055f5b0580cf68e3901e79ab6d"
      }
    }
  ]
}